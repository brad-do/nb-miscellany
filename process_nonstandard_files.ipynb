{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing unconventionally-delimited files in pandas\n",
    "Recently, a friend presented me with an interesting challenge.  He had a data file that he wanted to pull into a pandas dataframe; however, the file was substantially different from the CSVs and TSVs he normally parses with pandas.  Here's a representation of what he had to parse:<br/>\n",
    "<img src='commodities_log.jpg'></img><br/>\n",
    "So, how would someone such as myself go about parsing such a file into a dataframe?  Well, I would just do some parsing with Python.  Here's the solution I came up with:\n",
    "\n",
    "### Step 1: Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import the file as text and parse it into a list\n",
    "To start with, I split the file on those dotted lines.  Then, I iterate over each *entry* line-by-line.  With each iteration, I use a regular expression to find the timestamp value then I look for the other properties.  Ultimately, I append a list of the timestamp, the price, and the commodity name to my master list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delim = '-----------------------------------------------'\n",
    "ld = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "log_list = []\n",
    "\n",
    "with open('commodities.txt', 'r') as f:\n",
    "    log = f.read()\n",
    "    \n",
    "for entry in log.split(delim):\n",
    "    for line in entry.split('\\n'):\n",
    "        if ld.match(line):\n",
    "            d = datetime.datetime.strptime(line, '%Y-%m-%d %H:%M:%S')\n",
    "        elif len(line.strip()) > 0:\n",
    "            price = line.strip().split()[0]\n",
    "            commodity = line.strip().split()[1]\n",
    "            log_list.append([d, price, commodity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Read the master list into a new dataframe\n",
    "Once I finish iterating over the file and building out my log list, I can then properly pull it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_date</th>\n",
       "      <th>price</th>\n",
       "      <th>commodity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-13 16:00:00</td>\n",
       "      <td>1503.1</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-13 16:00:00</td>\n",
       "      <td>17.436</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-13 16:00:00</td>\n",
       "      <td>2.681</td>\n",
       "      <td>Copper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-12 16:00:00</td>\n",
       "      <td>1507.4</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-12 16:00:00</td>\n",
       "      <td>18.177</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             log_date   price commodity\n",
       "0 2019-09-13 16:00:00  1503.1      Gold\n",
       "1 2019-09-13 16:00:00  17.436    Silver\n",
       "2 2019-09-13 16:00:00   2.681    Copper\n",
       "3 2019-09-12 16:00:00  1507.4      Gold\n",
       "4 2019-09-12 16:00:00  18.177    Silver"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(log_list, columns=['log_date', 'price', 'commodity'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid purple;margin-top:1px;margin-bottom:1px\"></hr>\n",
    "### AWK Solution\n",
    "My friend happens to really like [awk](https://www.geeksforgeeks.org/awk-command-unixlinux-examples/).  While I was off coding my Python solution, he was busy writing an awk script to do the same.  It occurred to me, though, that even if he wanted to solve his problem with awk, he could do code it up and run it in Jupyter Notebook.  Here's how you might solve this same problem with awk:\n",
    "### Step 1: Develop the AWK script and write to disk\n",
    "The [writefile](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-writefile) magic word basically turns your Jupyter Notebook cell into a text editor where you can easily save your wort to a file.  Here, I'm coding the awk script and then writing it to the file *my_awk_script.awk*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_awk_script.awk\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_awk_script.awk\n",
    "BEGIN {\n",
    "    FS = \" \"\n",
    "    OFS = \",\"\n",
    "}\n",
    "{\n",
    "    if ( /^20/ )\n",
    "    {\n",
    "        dtstamp = $0\n",
    "    }\n",
    "    if ( NF = 2 )\n",
    "    {\n",
    "        price = $1\n",
    "        commodity = $2\n",
    "    }\n",
    "    if ( commodity ~ /^[0-9]/ )\n",
    "    {\n",
    "        print dtstamp,price,commodity\n",
    "    }\n",
    "}\n",
    "END {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run the awk file in a bash shell\n",
    "With my awk script done, I can execute it right from Jupyter Notebook with the help of the [bash](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-bash) magic word.  One cool thing about this magic word is that you can pipe the cell output to a variable for later processing.  Here, I'm pipe the results of the awk script to the variable *awk_output*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out awk_output\n",
    "gawk -f my_awk_script.awk commodities.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clean up the output and load it into a dataframe\n",
    "The output is one long string with *return* and *newline* characters denoting each new line.  I can do some list comprehension work and that string, though, and easily get it ready for reading into a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_date</th>\n",
       "      <th>price</th>\n",
       "      <th>commodity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-13 16:00:00\\r</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-12 16:00:00\\r</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-11 16:00:00\\r</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-10 16:00:00\\r</td>\n",
       "      <td>2019-09-10</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                log_date       price commodity\n",
       "0  2019-09-13 16:00:00\\r  2019-09-13  16:00:00\n",
       "1  2019-09-12 16:00:00\\r  2019-09-12  16:00:00\n",
       "2  2019-09-11 16:00:00\\r  2019-09-11  16:00:00\n",
       "3  2019-09-10 16:00:00\\r  2019-09-10  16:00:00\n",
       "4                               None      None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_log = [l.split(',') for l in awk_output.split('\\r\\n')]\n",
    "df2 = pd.DataFrame(parsed_log, columns=['log_date', 'price', 'commodity'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-09-13 16:00:00\\r,2019-09-13,16:00:00\\r\\n2019-09-12 16:00:00\\r,2019-09-12,16:00:00\\r\\n2019-09-11 16:00:00\\r,2019-09-11,16:00:00\\r\\n2019-09-10 16:00:00\\r,2019-09-10,16:00:00\\r\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the cell output is one long string with \\r\\n delimiters\n",
    "awk_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And there you go!  Two ways to parse an unconventional data file into a dataframe!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
